{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with specific column names\n",
    "corpus_df = pd.DataFrame(columns=['id', 'userurl', 'source', 'title', 'description', 'content', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append one row, fill by column name\n",
    "corpus_df = corpus_df.append(\n",
    "                    {'id': 0, 'userurl': 'url', 'source': 'source', 'title': 'title',\n",
    "                     'description': 'description', 'content': 'content',\n",
    "                     'keywords': 'keywords'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new column, being the concatenation of other columns\n",
    "corpus_df[\"text\"] = corpus_df[\"title\"].map(str) + ' ' + corpus_df[\"description\"] + ' ' + corpus_df[\n",
    "            \"content\"].map(str) + ' ' + corpus_df[\"keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "corpus_df = corpus_df.drop(['source', 'userurl', 'title', 'description', 'keywords', 'content'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dfs: https://stackoverflow.com/questions/32444138/combine-a-list-of-pandas-dataframes-to-one-pandas-dataframe\n",
    "df = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing/ Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write and read csv\n",
    "file_name = 'test.csv'\n",
    "corpus_df.to_csv(file_name, sep='\\t')\n",
    "# diff encoding\n",
    "corpus_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "# without index values\n",
    "corpus_df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# append\n",
    "with open(file_name, 'a') as f:\n",
    "    df.to_csv(f, header=False)\n",
    "# load\n",
    "df_corpus = pd.read_csv(file_name, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging \n",
    "comparison = pd.merge(results_sap, results_doc2vec, how='inner', on=['doc_id']) # if on is not specified, it is done on the index?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4530611/saving-and-loading-objects-and-using-pickle\n",
    "with open(r\"someobject.pickle\", \"wb\") as output_file:\n",
    "    cPickle.dump(d, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"someobject.pickle\", \"rb\") as input_file:\n",
    "    e = cPickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3108042/get-max-key-in-\n",
    "max(dict_m, key=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value by key, where the values are tuples!\n",
    "def get_url_key(url_to_find):\n",
    "    url_key = -1\n",
    "    for key, value in docs_dict.items():\n",
    "        if value[0][0] == url_to_find:\n",
    "            url_key = key\n",
    "    return url_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/32957708/python-pickle-error-unicodedecodeerror\n",
    "#https://stackoverflow.com/questions/9415785/merging-several-python-dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networ Communication\n",
    "- Interacting with the outside world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "!{sys.executable} -m pip install pyhdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pyhdb.connect(host=\"<mo-6770....>\", port=<port>, user=\"<user>\", password=\"<pass>\") # dummy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample query construction\n",
    "query = ''' SELECT \"USERURL\",\"TITLE\", \"CONTENT\", \"DESCRIPTION\", \"SOURCE\",\"KEYWORDS\"\n",
    "                    FROM REPO_.\"T.CONTENT\"   \n",
    "                    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many rows match the query\n",
    "N = cursor.execute(\"SELECT COUNT(*) FROM (\" + query + \")\").fetchone()[0]\n",
    "        print('Fetching ', N, ' documents...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work row by row\n",
    "for i in range(N):\n",
    "    try:\n",
    "        row = cursor.fetchone()\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print('Processing document ', i)\n",
    "        if row[0] is not None:\n",
    "            userurl = row[0]\n",
    "        else:\n",
    "            userurl = \"\"\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "    except UnicodeEncodeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch all rows\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://thepythonguru.com/fetching-records-using-fetchone-and-fetchmany/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'client'\n",
    "passw = 'dummypass'\n",
    "url = 'https://<search>.com/api/v1/search'\n",
    "headers = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = get_api_body(query)\n",
    "resp = requests.post(url, data=request_body, auth=(user, passw), headers=headers)\n",
    "resp_json = resp.json()\n",
    "results = resp_json['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_body(self, query):\n",
    "    data = ''' {\n",
    "            \"repository\": \"srh\",\n",
    "            \"type\": \"content\",\n",
    "            \"filters\": [{\n",
    "                    \"field\": \"CONTENT\",\n",
    "                    \"type\": \"fuzzy\",\n",
    "                    \"values\": [\"''' + query + '''\"],\n",
    "                    \"fuzzy\": {\n",
    "                        \"level\": 0.9,\n",
    "                        \"weight\": 0.2,\n",
    "                        \"parameters\": \"def\"\"\n",
    "                    },\n",
    "                    \"logicalOperator\": \"or\"\n",
    "                },\n",
    "                {\n",
    "                    \"field\": \"TITLE\",\n",
    "                    \"type\": \"fuzzy\",\n",
    "                    \"values\": [\"''' + query + '''\"],\n",
    "                    \"fuzzy\": {\n",
    "                        \"level\": 0.9,\n",
    "                        \"weight\": 1,\n",
    "                        \"parameters\": \"def\"\"\n",
    "                    }\n",
    "                }\n",
    "               '''\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results being an array of separate JSON objects\n",
    "def get_results_as_df(self, results):\n",
    "    results_df = pd.DataFrame(columns=['doc_id', 'userurl', 'title'])\n",
    "    # results[i] to access each subsequent/ separate JSON element\n",
    "    for i in range(len(results)):\n",
    "        results_df = results_df.append(\n",
    "            {'doc_id': doc_id, 'userurl': results[i]['USERURL'], 'title': results[i]['TITLE'],\n",
    "             'keywords': results[i]['KEYWORDS']}, ignore_index=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Utilization\n",
    "- usefull to check effects is htop, e.g. see https://peteris.rocks/blog/htop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results being a list of tuple(any) elements\n",
    "def get_pool_data(results):\n",
    "    \n",
    "    pool = mp.Pool()\n",
    "    deserialized_results_list = list(map(deserialize, results))\n",
    "    \n",
    "    results_mp = pool.map(preprocess_row, deserialized_results_list)   \n",
    "    df_global = pd.concat(results_mp)\n",
    "    \n",
    "    return df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/01.05-ipython-and-shell-commands.html\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    if i < 136000:\n",
    "        print('skiping ',i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "count = 1\n",
    "# Read in all files from the current directory, that match the prefix. \n",
    "for file in glob.glob(\"archive_sitemap_*\"):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty\n",
    "if not a:\n",
    "    print(\"List is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen and Sessions\n",
    "# https://stackoverflow.com/questions/1509677/kill-detached-screen-session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote connections\n",
    "#https://superuser.com/questions/23911/running-commands-on-putty-without-fear-of-losing-connection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
